{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6587b75-8286-484b-af94-00d2578b1839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebdf0feb-1c4c-45b4-8930-a4dc7fd1e9d6",
   "metadata": {
    "id": "Eoi65pKErfAU"
   },
   "source": [
    "# <<데이터분석과기계학습 2차 project 중간 보고서>>\n",
    "\n",
    "## 주제 : 어린이 위험 행동 인식 후, 운전자에게 먼저 알러주는 서비스\n",
    "\n",
    "1차에 발표했던 행동인식이 과연 이 주제의 목적에 적합한가에 대한 고민을 많이 해봤다.\n",
    "\n",
    "그리고 내가 현재 직면한 하드웨어의 한계를 생각했을 때에도 어려움이 크다고 판단하여,\n",
    "\n",
    "cctv 데이터를 활용하여 어린이와 어른을 구분하고\n",
    "\n",
    "운전자에게 어린이 보호구역에 어린이가 존재한다는 것을 알리는 서비스로 추진하자고 약간의 변동을 줬다.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded7d4b-04c7-44a7-9725-5bd00bcafbc1",
   "metadata": {
    "id": "V-Jxzage1wYp",
    "tags": []
   },
   "source": [
    "# *$데이터 수집*\n",
    "\n",
    "aihub.or.kr 사이트에서 어린이 보호구역 내 어린이 도로보행 위험행동 영상의 데이터를 가져왔다.\n",
    "\n",
    "이 데이터는 총 5.95TB의 용량을 가지고 있어, 일부 데이터인 하나의 폴더만 가져와서 분석하기로 결정했다.\n",
    "\n",
    "https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=169\n",
    "\n",
    "그리고 이 하나의 폴더도 용량이 커, 이 폴더 속에 있는 영상데이터들 중에 어린이가 많은 영상 20개를 추려 분석을을 진행할할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b877d97-73d2-449a-b461-0b54e2b46b16",
   "metadata": {
    "id": "r_7na2CwNql9",
    "outputId": "ad6678e0-cebf-4343-d918-4ac8ddea2034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    }
   ],
   "source": [
    "data_txt = open(\"./cctv_data/Training/training_dataset.txt\",'r') #validation도 따로 진행함.\n",
    "data = data_txt.read().splitlines()\n",
    "result1 = []\n",
    "for i in data:\n",
    "    line = i.split()\n",
    "    if (\"./cctv_data/Training/label_data/\"+line[0][:19]+'.json') in result1:\n",
    "        continue\n",
    "    else:\n",
    "        result1.append(\"./cctv_data/Training/label_data/\"+line[0][:19]+'.json')\n",
    "print(len(result1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d2963-c346-4598-af47-ed5c46cb12af",
   "metadata": {
    "id": "3tlTNHlt8Nzv"
   },
   "source": [
    "# *$Data Processing*\n",
    "\n",
    "### >303개의 영상과 json파일을 학습시키기에는 무리가 있다고 판단하였다.\n",
    "303개의 영상을 frame단위로 캡처하게 된다면, 30만개 이상의 사진이 저장되기 때문에 무리가 있다.\n",
    "\n",
    "\n",
    "그러기에 나는 주제에 관련된 데이터만 추출하기 위해\n",
    "\n",
    "\n",
    "어린이가 존재하는 영상만 추출한 후, 전처리를 진행해야겠다고 판단함.\n",
    "\n",
    "어린이가 많은 영상 20개를 추리기 위해 아래 processing_annotations함수를 영상의 label데이터들이 \n",
    "\n",
    "있는 json 파일을 모두 열어서 one hot encoding 개념을 활용해서 하나의 txt파일에 저장했다.\n",
    "\n",
    "train data는 training_dataset.txt\n",
    "\n",
    "validation data는 validation_dataset.txt에 저장하여 활용할 수 있도록 했다.\n",
    "\n",
    "이 txt파일에는 각 프레임별 캡처 사진에 대한 정보가 있는데,\n",
    "\n",
    "\"파일명.json 1 0 0 1 0 \"... 이런식으로 각 해당하는 항목에 1을 넣어 희소행렬처럼 생겼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6c70a-998d-42b6-8638-9214fbafd4c8",
   "metadata": {
    "id": "b-z7_qEaNql9",
    "outputId": "a5b1e3ac-cd2a-4d93-b09c-332916d6d639",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-07_08-15-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-07_16-00-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-01_18-48-00_wed_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-09_20-18-00_thu_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-07_14-36-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-08_10-06-00_wed_sunny_out_do-sa_C0001-1_고1.json\n",
      "2021-09-08_09-18-00_wed_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-07_22-21-00_tue_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-07_09-42-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-07_11-24-00_tue_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-09_09-51-00_thu_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-02_09-09-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-07_22-45-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-03_08-39-00_fri_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-07_08-42-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-07_22-48-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-06_17-18-00_mon_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-08_09-27-00_wed_sunny_out_do-sa_C0001-1_고1.json\n",
      "2021-09-09_09-33-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-08_23-21-00_wed_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-08_21-12-00_wed_sunny_out_ye-ma_CD0001.json\n",
      ".DS_Store\n",
      "2021-09-08_09-00-00_wed_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-01_19-24-00_wed_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-08_11-00-00_wed_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-08_07-45-00_wed_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-03_08-18-00_fri_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-06_16-18-00_mon_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-09_09-15-00_thu_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-03_12-36-00_fri_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-06_12-18-00_mon_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-07_07-18-00_tue_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-08_09-45-00_wed_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-02_17-39-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-06_08-27-00_mon_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-09_10-33-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-04_17-45-00_sat_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-04_16-06-00_sat_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-08_10-03-00_wed_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-01_08-54-00_wed_rainy_out_do-sa_C0053-1.json\n",
      "2021-09-08_23-15-00_wed_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-08_09-18-00_wed_sunny_out_do-sa_C0001-1_고1.json\n",
      "2021-09-09_21-36-00_thu_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-07_17-06-00_tue_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-05_16-27-00_sun_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-09_22-24-00_thu_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-09_08-39-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-09_16-30-00_thu_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-09_20-51-00_thu_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-06_08-12-00_mon_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-09_11-03-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-08_16-27-00_wed_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-09_16-54-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-07_09-36-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-09_20-54-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-05_16-00-00_sun_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-08_22-39-00_wed_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-06_08-33-00_mon_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-02_19-24-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-07_09-12-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-05_16-24-00_sun_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-06_08-24-00_mon_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-03_07-51-00_fri_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-07_08-33-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-06_08-00-00_mon_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-07_08-30-00_tue_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-03_08-30-00_fri_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-06_07-18-00_mon_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-02_19-03-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-09_23-24-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-03_12-03-00_fri_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-09_14-45-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-07_09-03-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-07_08-03-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-09_10-45-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-02_10-18-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-03_12-54-00_fri_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-02_09-51-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-06_08-30-00_mon_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-07_22-06-00_tue_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-06_07-27-00_mon_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-08_09-30-00_wed_sunny_out_do-sa_C0001-1_고1.json\n",
      "2021-09-08_09-18-00_wed_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-07_20-27-00_tue_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-09_23-42-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-08_22-00-00_wed_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-08_07-00-00_wed_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-09_11-15-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-08_11-21-00_wed_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-08_10-06-00_wed_sunny_out_do-sa_C0001-1_고2.json\n",
      "2021-09-02_17-12-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-09_09-39-00_thu_sunny_out_do-sa_C0053-1.json\n",
      "2021-09-07_21-45-00_tue_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-08_09-06-00_wed_sunny_out_do-sa_C0001-1_고1.json\n",
      "2021-09-06_11-00-00_mon_sunny_out_ye-ma_CD0002.json\n",
      "2021-09-06_12-21-00_mon_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-02_11-12-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-06_12-06-00_mon_cloudy_out_do-sa_C0053-1.json\n",
      "2021-09-02_17-24-00_thu_sunny_out_ye-ma_CD0001.json\n",
      "2021-09-07_07-12-00_tue_sunny_out_ye-ma_CD0001.json\n"
     ]
    }
   ],
   "source": [
    "#파일 이름을 간단하게 변경! (파일 날짜와 시간만 사용.)\n",
    "import os\n",
    "\n",
    "\n",
    "path = \"./cctv_data/Training/label_data\" #validation도 따로 진행함.\n",
    "\n",
    "file_list = os.listdir(path)\n",
    "file_list\n",
    "\n",
    "for file in file_list: # 전체 파일 리스트에 대해서 수행\n",
    "    print(file)\n",
    "    src = os.path.join(path, file) # 기존 파일 경로\n",
    "    dst_name = file[:19]+'.json' # 이름 수정 json 파일은 json을 추가 mp4는 mp4를 추가\n",
    "    dst = os.path.join(path, dst_name) # 바뀐 이름으로 저장할 경로\n",
    "    os.rename(src, dst) # rename 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08978803-e840-4f6b-b981-05faab8a9a3a",
   "metadata": {
    "id": "SE5XsrZDNql-",
    "outputId": "0895408f-7ee5-46a2-a525-074677f3e1df",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cctv_data/Validation/label_data/2021-09-06_08-12-00.json : 150 / 539\n",
      "./cctv_data/Validation/label_data/2021-09-03_07-51-00.json : 98 / 803\n",
      "./cctv_data/Validation/label_data/2021-09-05_16-24-00.json : 80 / 2484\n",
      "./cctv_data/Validation/label_data/2021-09-07_21-45-00.json : 80 / 954\n",
      "./cctv_data/Validation/label_data/2021-09-08_09-18-00.json : 73 / 3202\n"
     ]
    }
   ],
   "source": [
    "#용량 부족으로 인해 어린이가 존재하지 않는 영상 제거 하는 전처리 작업\n",
    "data_txt = open(\"./cctv_data/Validation/validation_dataset.txt\",'r') #train도 따로 진행함.\n",
    "data = data_txt.read().splitlines()\n",
    "result = {}\n",
    "for i in data:\n",
    "    line = i.split()\n",
    "    if (line[3] == '1' or line[4] == \"1\"):\n",
    "        \n",
    "        if (\"./cctv_data/Validation/label_data/\"+line[0][:19]+'.json') in result.keys():\n",
    "            result[\"./cctv_data/Validation/label_data/\"+line[0][:19]+'.json'] += 1\n",
    "            continue\n",
    "        else:\n",
    "            result[\"./cctv_data/Validation/label_data/\"+line[0][:19]+'.json'] = 1\n",
    "            # result.append(\"./cctv_data/Validation/label_data/\"+line[0][:19]+'.json')\n",
    "\n",
    "result_asc = sorted(result.items(), key = lambda item: item[1],reverse = True)\n",
    "choice_file = []\n",
    "for key, value in result_asc[:5]: #validation은 child가 가장 많은 상위 5개를 train은 20개를 choice_file 리스트에 넣었다.\n",
    "    total = 0\n",
    "    for d in data:\n",
    "        b = key.split(\"/\")[-1][:-5]\n",
    "        if b in d:\n",
    "            total += 1\n",
    "    print(key, \":\", value,\"/\",total)\n",
    "    choice_file.append(key)\n",
    "#result\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07062a56-f6d1-4322-8f84-2ef859e9f816",
   "metadata": {
    "id": "KBc3bYluNql-"
   },
   "source": [
    "### --위 리스트 choice_file에서 선정된 파일만 놔두고 나머지 데이터들을 제거하자.\n",
    "\n",
    "train은 20개 / validation은 5개 파일만 보존"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c6983-b5bc-4993-a19b-5da8c7d686bf",
   "metadata": {
    "id": "V8tL-siINql-",
    "outputId": "78df653e-c87f-4330-bf29-3713a90b357d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cctv_data/Validation/label_data/2021-09-05_16-24-00.json 보존\n",
      "./cctv_data/Validation/label_data/2021-09-06_08-12-00.json 보존\n",
      "./cctv_data/Validation/label_data/2021-09-03_07-51-00.json 보존\n",
      "./cctv_data/Validation/label_data/2021-09-07_21-45-00.json 보존\n",
      "./cctv_data/Validation/label_data/2021-09-08_09-18-00.json 보존\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"./cctv_data/Validation/label_data\" #train도 따로 진행함.\n",
    "\n",
    "data_list = os.listdir(path)\n",
    "data_list\n",
    "count = 0\n",
    "\n",
    "for file in data_list:\n",
    "    file_path = \"./cctv_data/Validation/label_data/\" + file\n",
    "    if file_path in choice_file:\n",
    "        #print(\"yes\")\n",
    "        if os.path.exists(file_path):\n",
    "            print(file_path,\"보존\")\n",
    "            count+=1\n",
    "            continue\n",
    "    else:\n",
    "        if file_path in ['./cctv_data/Validation/label_data/.ipynb_checkpoints','./cctv_data/Validation/label_data/.ipynb_checkpoints.json']:\n",
    "            continue\n",
    "        elif os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22dbacd-40b0-4453-b547-31e7a4c8b6b7",
   "metadata": {
    "id": "O0v9dY7qsOps"
   },
   "source": [
    "## *#class & bbox 좌표 데이터 구성*\n",
    "\n",
    "데이터를 모델에 돌리기 전에 모델에 적합한 형태로 구성해줘야한다.\n",
    "\n",
    "우선 수집한 데이터의 형태는 label dataset이 json파일로 각 프레임마다 어떤 객체가 어디 좌표에 있는지 어떤 옷을 입고 있는지, 나이대, 성별, 어디로 향하는지가 담겨있다.\n",
    "\n",
    "여기서 내가 원하는 부분은 사람인 객체의 나이대와 bounding box 좌표다.\n",
    "\n",
    "그렇기에, 아래 코드를 활용하여 json 파일에서 원하는 정보만 가져와 txt파일에 담았다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba7884f-d06a-4525-a2ab-c9abb1b1c430",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZbdHQNbpNql_",
    "outputId": "fc6bcdf0-6f87-4373-a744-9a70c4abb342",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_18-12-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-06_16-00-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_19-42-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_16-33-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-07_16-09-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_18-51-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-07_18-21-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-07_16-24-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-06_19-03-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_18-48-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_19-06-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-06_18-06-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_16-45-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_08-15-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-09_07-48-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_08-00-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_08-12-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-08_07-48-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-02_07-54-00.json\n",
      "/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label_data/2021-09-09_07-51-00.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from operator import itemgetter\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print('Error: Creating directory. ' +  directory)\n",
    "\n",
    "def processing_annotations(json_path):\n",
    "    with open(json_path, 'r', encoding='utf8') as json_f:\n",
    "        json_data = json.load(json_f)\n",
    "\n",
    "        categories = json_data[\"categories\"]\n",
    "\n",
    "        annotations = json_data[\"annotations\"]\n",
    "        sort_annotations = sorted(annotations, key=itemgetter(\"frame\"))\n",
    "        process_annotations = []\n",
    "        for annotation in sort_annotations:\n",
    "            if annotation[\"id\"][0] == \"p\" or annotation[\"id\"][0] == \"a\":\n",
    "                annotation[\"age\"] = [category[\"age\"] for category in categories if\n",
    "                                     category[\"id\"] == annotation[\"id\"]][0]\n",
    "                process_annotations.append(annotation)\n",
    "\n",
    "    return process_annotations\n",
    "\n",
    "def extract_frame(video_path, process_annotations, file_name,total_frame):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_no = 0\n",
    "    checked_idx = 0\n",
    "    cap_img = []\n",
    "    if cap.isOpened():\n",
    "        while True:\n",
    "            ret, img = cap.read()\n",
    "            if ret:\n",
    "                split_process_annotations = process_annotations[checked_idx:]\n",
    "                for process_annotation in split_process_annotations:\n",
    "\n",
    "                    if process_annotation[\"frame\"] > frame_no:\n",
    "                        break\n",
    "                    if process_annotation[\"frame\"] % 10 == 0:\n",
    "                        bbox = process_annotation[\"bbox\"]\n",
    "                        crop_img = img.copy()\n",
    "                        jpg_file_name = file_name + \"_\" + str(process_annotation[\"frame\"]) + \".jpg\"\n",
    "                        cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                        age_w = {\"child\": \"1\", \"teenager\": \"1\", \"adult\": \"0\", \"senior\": \"0\"}.get(process_annotation[\"age\"])\n",
    "\n",
    "                        dataset_line = age_w + \" \" + str(bbox[0])  + \" \" + str(bbox[1])  + \" \" + str(bbox[2]) + \" \" + str(bbox[3]) + \"\\n\"\n",
    "                        label_txt = \"/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label/\"+jpg_file_name[:-4]+\".txt\"\n",
    "\n",
    "                        if jpg_file_name in cap_img:\n",
    "\n",
    "                            with open(label_txt, 'a', encoding='utf8') as train_f:\n",
    "                                  train_f.write(dataset_line)\n",
    "\n",
    "                        else:\n",
    "                            cv2.imwrite('/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/img/' + jpg_file_name, crop_img)\n",
    "                            cap_img.append(jpg_file_name)\n",
    "                            with open(label_txt, 'a', encoding='utf8') as train_f:\n",
    "                                  train_f.write(dataset_line)\n",
    "\n",
    "                    checked_idx += 1\n",
    "                    \n",
    "                frame_no += 1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        print(\"can't open video.\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def processing(video_dir):\n",
    "    for (root, dirs, files) in os.walk(video_dir):\n",
    "        for file in files:\n",
    "\n",
    "            file_name, extension = os.path.splitext(file)\n",
    "\n",
    "            if extension == \".mp4\":\n",
    "\n",
    "                json_path = root[:-10] + \"/\"+'label_data/'+ file_name + \".json\"\n",
    "                with open(json_path, 'r', encoding='utf8') as json_f:\n",
    "                    json_data = json.load(json_f)\n",
    "                    video_impo = json_data[\"video\"]\n",
    "                    total_frame = video_impo[\"total_frame\"]\n",
    "                print(json_path)\n",
    "                if os.path.exists(json_path):\n",
    "                    process_annotations = processing_annotations(json_path)\n",
    "\n",
    "                else:\n",
    "                    with open(\"./error.txt\", 'w', encoding='utf8') as error_f:\n",
    "                        error_f.write(root + \"/\" + file + \"\\n\")\n",
    "                    print(\"Error : not matched \" + root + \"/\" + file)\n",
    "                    continue\n",
    "\n",
    "                video_path = root + \"/\" + file\n",
    "                extract_frame(video_path, process_annotations, file_name,total_frame)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    createFolder(\"/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/img\")\n",
    "    createFolder(\"/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/label\")\n",
    "\n",
    "    video_dir = \"/content/drive/MyDrive/pytorch_advanced/objectdetection/data/cctv_data/Training/main_data\"\n",
    "    processing(video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d562e-636a-4479-98e8-be844fb3063e",
   "metadata": {
    "id": "lqIztmg6Nql_",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 결론!!\n",
    "\n",
    "train img data는 933개\n",
    "\n",
    "validation img data는 193개로 만들어졌다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
